# -*- coding: UTF-8 -*-.
import argparse
import os
import csv
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC

N_GOODWARES = 100
N_MALWARES = 1000
TEST_SIZE = 0.1
FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics",
             "DllCharacteristics", "Entropy", "FileAlignment", "FileType", "FormatedTimeDateSteamp", "Fuzzy", "Identify", "ImageBase", "ImportedDlls", "ImportedSymbols", "MD5", "Machine", "Magic", "Name", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PE_TYPE", "PointerToSymbolTable", "SHA1", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData", "SizeOfOptionalHeader", "SizeOfUninitializedData", "TimeDateStamp"]

USED_FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics",
                  "DllCharacteristics", "Entropy", "FileAlignment", "ImageBase", "Machine", "Magic", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PE_TYPE", "PointerToSymbolTable", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData", "SizeOfOptionalHeader", "SizeOfUninitializedData", "TimeDateStamp"]

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    params = parser.parse_args()
    return params.goodwares_csv, params.malwares_csv

def read_file(input_file):
    with open(input_file, 'rb') as file:
        reader = csv.DictReader(file)
        features = []
        for row in reader:
            example = []
            for f in USED_FEATURES:
                example.append(row[f])
            features.append(example)
    return features

# get params
gw_csv, mw_csv = params()

# read goodwares and malwares
gw = read_file(gw_csv)
mw = read_file(mw_csv)

# create label arrays
print "Goodwares:",len(gw)
print "Malwares:", len(mw)

gw_label = np.zeros(len(gw))
mw_label = np.ones(len(mw))

# cross validation
gw_X_train, gw_X_test, gw_y_train, gw_y_test = train_test_split(gw,gw_label,test_size=TEST_SIZE)
mw_X_train, mw_X_test, mw_y_train, mw_y_test = train_test_split(mw,mw_label,test_size=TEST_SIZE)

# create train and test sets
X_train = []
X_test = []
for i in gw_X_train:
    X_train.append(i)
for i in mw_X_train:
    X_train.append(i)
for i in gw_X_test:
    X_test.append(i)
for i in mw_X_test:
    X_test.append(i)
y_train = []
y_test = []
for i in gw_y_train:
    y_train.append(i)
for i in mw_y_train:
    y_train.append(i)
for i in gw_y_test:
    y_test.append(i)
for i in mw_y_test:
    y_test.append(i)

# use in a classifier
clf = SVC()
clf.fit(X_train, y_train)
pred = clf.predict(X_test)
print accuracy_score(y_test, pred)
print confusion_matrix(y_test, pred)
