# -*- coding: UTF-8 -*-.
# http://pt.slideshare.net/roselmamendes/desenvolvendo-web-crawlerscraper-com-python
from bs4 import BeautifulSoup
import requests
import re
import os
import mechanize
from subprocess import call

goodwares_folder = "./goodwares"

def get_page(url):
    br = mechanize.Browser()
    br.set_handle_equiv(True)
    br.set_handle_gzip(False)
    br.set_handle_redirect(True)
    br.set_handle_referer(True)
    br.set_handle_robots(False)
    br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)
    br.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 5.1; rv:14.0) Gecko/20100101 Firefox/14.0.1')]
    br.open(url)
    url_soup = BeautifulSoup(br.response().get_data(), "lxml")
    return url_soup

if not os.path.exists(goodwares_folder):
    os.makedirs(goodwares_folder)
os.chdir(goodwares_folder)

base_url = "http://sourceforge.net"
url = 'http://sourceforge.net/directory/os:windows/?page='
for i in range(1,2):
    url_soup = get_page(url+str(i))
    for url_a in url_soup.findAll('a', {'itemprop':'url'}):
        # build software page from sourceforge
        item_url = base_url+url_a['href']
        # remove any ?source= from url
        regex = r"(\?source=)\w+.\w+"
        item_url = re.sub(regex, "", item_url)
        # build download page url
        download_url = item_url + "files/latest/download"
        # get download page
        download_soup = get_page(download_url)
        for url_download in download_soup.findAll('a', {'class':'direct-download'}):
            download_link = url_download['href']
            print download_link
            call(["wget", download_link])
        print
